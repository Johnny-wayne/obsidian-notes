
Quando você selecionar uma linha na transcrição, será direcionado à seção equivalente no vídeo

Como vimos, algoritmos de aprendizado de máquina supervisionados podem classificar dados. Algoritmos de aprendizado de máquina não supervisionados podem agrupar dados. Agora veremos um conjunto bem diferente de algoritmos que se baseiam em probabilidade condicional. Como um elemento afeta a probabilidade de outro ocorrer. O algoritmo mais usado para essa análise é o bayesiano, que se baseia na teoria estatística de Bayes. Naive Bayes é um dos algoritmos bayesianos de aprendizado de máquina mais usados. Foi batizado de ingênuo por pressupor que os preditores são independentes entre si. É usado principalmente para classificação binária ou multiclasse. Voltemos ao abrigo de animais em Chicago. Imagine que queiramos classificar todos os cães do abrigo por raça. Lembre-se: há centenas de raças de cães. Além disso, a maioria dos cães é uma mistura de raças. Vamos examinar esse problema com o algoritmo de aprendizado de máquina Naive Bayes. Para começar, criaremos três classes de raças de cães: terrier, caça e esportivos. Para cada categoria, teremos três preditores: comprimento do pelo, altura e peso. Lembre-se: alguns dos preditores estarão estreitamente autocorrelacionados. É mais provável que um cão alto seja mais pesado. Mas o Naive Bayes considera cada preditor de forma independente. Lembre-se: é por isso que ele é chamado de ingênuo. Depois de definir as classes e preditores, o algoritmo de aprendizado de máquina Naive Bayes inicia verificando a “probabilidade dos preditores de classe”. É quando verifica cada preditor independente e define a probabilidade de o cão pertencer a cada classe. Vamos ver o que ocorre ao tentarmos identificar um cão desconhecido. O primeiro preditor a analisar é o comprimento do pelo. O algoritmo verifica a probabilidade de um cão com esse comprimento de pelo pertencer às três classes. Ele descobre que um cão com esse comprimento de pelo tem 40% de chance de ser um terrier, 10% de chance de ser um cão de caça e 50% de chance de ser um cão esportivo. O próximo passo é analisar a altura do cão desconhecido. Reforçando, o Naive Bayes não correlaciona o comprimento do pelo com a altura do cão. Ele analisa esse preditor de forma independente e calcula a probabilidade de o cão desconhecido pertencer a cada classe. Então, ele analisa os dados de treinamento e descobre que há 20% de chance de ser um terrier, 10% de chance de ser um cão de caça e 70% de chance de ser um cão esportivo. A última coisa a verificar é o peso do cão desconhecido. Pode parecer um preditor estranho por estar relacionado à altura. Mas o Naive Bayes avalia a probabilidade de cada preditor de forma independente. Ele analisa os dados de treinamento e descobre que há 10% de chance de ser um terrier, 5% de chance de ser um cão de caça e 85% de chance de ser um cão esportivo. Agora você tem uma tabela com as probabilidades dos preditores de classe do cão desconhecido. Vemos que provavelmente é um cão de caça. Mas lembre-se, a maioria dos problemas de aprendizado de máquina lida com terabytes ou até petabytes de dados de cães, e tenta classificar milhões de cães desconhecidos. Então, para classificar o cão, você pode usar a função de multiplicação ponderada. Como é uma função ponderada, a primeira coisa a fazer é criar pesos. Você decide qual dos preditores é o mais preditivo, podendo definir os pesos analisando os dados de treinamento. Você também pode ajustá-los, se isso melhorar a precisão. Usarei peso três para pelos e dois para peso e altura. Assim, para a função de multiplicação ponderada, multiplique o preditor pelo peso.

---
#machine-learning 